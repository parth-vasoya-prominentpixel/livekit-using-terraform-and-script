name: ğŸš€ LiveKit Pipeline (Auto)

on:
  workflow_dispatch:
    inputs:
      action:
        description: 'Action to perform'
        required: true
        default: 'deploy'
        type: choice
        options:
          - deploy
          - destroy
      environment:
        description: 'Environment'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - uat
          - prod
      skip_prerequisites:
        description: 'Skip Prerequisites Check'
        required: false
        default: false
        type: boolean
      skip_terraform_plan:
        description: 'Skip Terraform Plan'
        required: false
        default: false
        type: boolean
      skip_terraform_apply:
        description: 'Skip Terraform Apply'
        required: false
        default: false
        type: boolean
      skip_load_balancer:
        description: 'Skip Load Balancer Setup'
        required: false
        default: false
        type: boolean
      skip_livekit:
        description: 'Skip LiveKit Deployment'
        required: false
        default: false
        type: boolean

env:
  AWS_REGION: us-east-1

permissions:
  id-token: write
  contents: read

jobs:
  # Step 1: Prerequisites (Optional)
  prerequisites:
    name: ğŸ”§ Step 1 - Prerequisites
    runs-on: ubuntu-latest
    if: ${{ inputs.action == 'deploy' && !inputs.skip_prerequisites }}
    environment: livekit-poc-${{ inputs.environment }}-prerequisites
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          role-session-name: GitHubActions-Prerequisites-${{ github.run_id }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Tools
        run: |
          # Setup Terraform
          wget -q https://releases.hashicorp.com/terraform/1.10.3/terraform_1.10.3_linux_amd64.zip
          unzip -q terraform_1.10.3_linux_amd64.zip
          sudo mv terraform /usr/local/bin/
          
          # Setup kubectl
          curl -LO "https://dl.k8s.io/release/v1.30.0/bin/linux/amd64/kubectl"
          sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
          
          # Setup Helm
          curl -fsSL https://get.helm.sh/helm-v3.16.3-linux-amd64.tar.gz | tar -xz
          sudo mv linux-amd64/helm /usr/local/bin/
          
          # Setup eksctl
          curl -sLO "https://github.com/eksctl-io/eksctl/releases/download/v0.191.0/eksctl_Linux_amd64.tar.gz"
          tar -xzf eksctl_Linux_amd64.tar.gz
          sudo mv eksctl /usr/local/bin/

      - name: Run Prerequisites Script
        working-directory: scripts
        run: |
          chmod +x 00-prerequisites.sh
          ./00-prerequisites.sh

  # Step 2: Terraform Plan (Optional)
  terraform-plan:
    name: ğŸ“‹ Step 2 - Terraform Plan
    runs-on: ubuntu-latest
    needs: [prerequisites]
    if: ${{ always() && inputs.action == 'deploy' && !inputs.skip_terraform_plan && (needs.prerequisites.result == 'success' || inputs.skip_prerequisites) }}
    environment: livekit-poc-${{ inputs.environment }}-terraform-plan
    outputs:
      plan-output: ${{ steps.plan.outputs.plan_output }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          role-session-name: GitHubActions-Terraform-Plan-${{ github.run_id }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform-version: 1.10.3

      - name: Terraform Plan
        id: plan
        working-directory: resources
        run: |
          echo "ğŸ“‹ Running Terraform Plan..."
          
          terraform init -backend-config="../environments/livekit-poc/${{ env.AWS_REGION }}/${{ inputs.environment }}/backend.tfvars"
          
          terraform plan \
            -var-file="../environments/livekit-poc/${{ env.AWS_REGION }}/${{ inputs.environment }}/inputs.tfvars" \
            -var="deployment_role_arn=${{ secrets.DEPLOYMENT_ROLE_ARN }}" \
            -out=tfplan
          
          echo "âœ… Terraform plan completed successfully!"

  # Step 3: Terraform Apply (Optional)
  terraform-apply:
    name: ğŸš€ Step 3 - Terraform Apply
    runs-on: ubuntu-latest
    needs: [terraform-plan]
    if: ${{ always() && inputs.action == 'deploy' && !inputs.skip_terraform_apply && (needs.terraform-plan.result == 'success' || inputs.skip_terraform_plan) }}
    environment: livekit-poc-${{ inputs.environment }}-terraform-apply
    outputs:
      cluster-name: ${{ steps.apply.outputs.cluster_name }}
      redis-endpoint: ${{ steps.apply.outputs.redis_endpoint }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          role-session-name: GitHubActions-Terraform-Apply-${{ github.run_id }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform-version: 1.10.3

      - name: Terraform Apply
        id: apply
        working-directory: resources
        run: |
          echo "ğŸš€ Applying Terraform configuration..."
          
          terraform init -backend-config="../environments/livekit-poc/${{ env.AWS_REGION }}/${{ inputs.environment }}/backend.tfvars"
          
          terraform plan \
            -var-file="../environments/livekit-poc/${{ env.AWS_REGION }}/${{ inputs.environment }}/inputs.tfvars" \
            -var="deployment_role_arn=${{ secrets.DEPLOYMENT_ROLE_ARN }}" \
            -out=tfplan
          
          terraform apply tfplan
          
          # Get outputs
          CLUSTER_NAME=$(terraform output -raw cluster_name)
          REDIS_ENDPOINT=$(terraform output -raw redis_cluster_endpoint)
          
          echo "cluster_name=$CLUSTER_NAME" >> $GITHUB_OUTPUT
          echo "redis_endpoint=$REDIS_ENDPOINT" >> $GITHUB_OUTPUT
          
          echo "âœ… Infrastructure deployed successfully!"
          echo "ğŸ“Š Cluster: $CLUSTER_NAME"
          echo "ğŸ“Š Redis: $REDIS_ENDPOINT"

  # Step 4: Setup Load Balancer Controller (Optional)
  setup-load-balancer:
    name: âš–ï¸ Step 4 - Setup Load Balancer Controller
    runs-on: ubuntu-latest
    needs: [terraform-apply]
    if: ${{ always() && inputs.action == 'deploy' && !inputs.skip_load_balancer && (needs.terraform-apply.result == 'success' || inputs.skip_terraform_apply) }}
    environment: livekit-poc-${{ inputs.environment }}-setup-load-balancer
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          role-session-name: GitHubActions-Setup-LB-${{ github.run_id }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Tools
        run: |
          # Install kubectl
          curl -LO "https://dl.k8s.io/release/v1.30.0/bin/linux/amd64/kubectl"
          sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
          
          # Install Helm
          curl -fsSL https://get.helm.sh/helm-v3.16.3-linux-amd64.tar.gz | tar -xz
          sudo mv linux-amd64/helm /usr/local/bin/
          
          # Install eksctl
          curl -sLO "https://github.com/eksctl-io/eksctl/releases/download/v0.191.0/eksctl_Linux_amd64.tar.gz"
          tar -xzf eksctl_Linux_amd64.tar.gz
          sudo mv eksctl /usr/local/bin/

      - name: Get Cluster Name
        id: cluster
        run: |
          if [ "${{ inputs.skip_terraform_apply }}" = "true" ]; then
            # If terraform was skipped, get cluster name from environment
            echo "cluster_name=lp-eks-livekit-use1-${{ inputs.environment }}" >> $GITHUB_OUTPUT
          else
            # Use output from terraform-apply
            echo "cluster_name=${{ needs.terraform-apply.outputs.cluster-name }}" >> $GITHUB_OUTPUT
          fi

      - name: Wait for Cluster Ready
        run: |
          echo "â³ Waiting for cluster to be ready..."
          CLUSTER_NAME="${{ steps.cluster.outputs.cluster_name }}"
          
          # Reduced wait time
          sleep 20
          
          # Check cluster status
          for i in {1..5}; do
            CLUSTER_STATUS=$(aws eks describe-cluster --name "$CLUSTER_NAME" --region "${{ env.AWS_REGION }}" --query 'cluster.status' --output text 2>/dev/null || echo "UNKNOWN")
            echo "ğŸ“‹ Cluster status: $CLUSTER_STATUS (attempt $i/5)"
            
            if [ "$CLUSTER_STATUS" = "ACTIVE" ]; then
              echo "âœ… Cluster is ACTIVE and ready"
              break
            elif [ "$CLUSTER_STATUS" = "CREATING" ]; then
              echo "â³ Cluster still creating, waiting 20 seconds..."
              sleep 20
            else
              echo "âŒ Unexpected cluster status: $CLUSTER_STATUS"
              if [ $i -eq 5 ]; then
                echo "âŒ Cluster not ready after 5 attempts"
                exit 1
              fi
            fi
          done

      - name: Run Load Balancer Setup Script
        working-directory: scripts
        run: |
          chmod +x 02-setup-load-balancer.sh
          CLUSTER_NAME="${{ steps.cluster.outputs.cluster_name }}" \
          AWS_REGION="${{ env.AWS_REGION }}" \
          ./02-setup-load-balancer.sh

  # Step 5: Deploy LiveKit (Optional)
  deploy-livekit:
    name: ğŸ¥ Step 5 - Deploy LiveKit
    runs-on: ubuntu-latest
    needs: [terraform-apply, setup-load-balancer]
    if: ${{ always() && inputs.action == 'deploy' && !inputs.skip_livekit && (needs.setup-load-balancer.result == 'success' || inputs.skip_load_balancer) }}
    environment: livekit-poc-${{ inputs.environment }}-deploy-livekit
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          role-session-name: GitHubActions-Deploy-LiveKit-${{ github.run_id }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Tools
        run: |
          curl -LO "https://dl.k8s.io/release/v1.30.0/bin/linux/amd64/kubectl"
          sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
          curl -fsSL https://get.helm.sh/helm-v3.16.3-linux-amd64.tar.gz | tar -xz
          sudo mv linux-amd64/helm /usr/local/bin/
          
          # Install Terraform for Redis endpoint retrieval if needed
          wget -q https://releases.hashicorp.com/terraform/1.10.3/terraform_1.10.3_linux_amd64.zip
          unzip -q terraform_1.10.3_linux_amd64.zip
          sudo mv terraform /usr/local/bin/

      - name: Run LiveKit Deployment Script
        working-directory: scripts
        run: |
          chmod +x 03-deploy-livekit.sh
          
          # Determine cluster name and Redis endpoint
          if [ "${{ inputs.skip_terraform_apply }}" = "true" ]; then
            CLUSTER_NAME="lp-eks-livekit-use1-${{ inputs.environment }}"
            # Get Redis endpoint from existing Terraform state
            cd ../resources
            terraform init -backend-config="../environments/livekit-poc/${{ env.AWS_REGION }}/${{ inputs.environment }}/backend.tfvars" || true
            REDIS_ENDPOINT=$(terraform output -raw redis_cluster_endpoint 2>/dev/null || echo "")
            cd ../scripts
            
            if [ -z "$REDIS_ENDPOINT" ]; then
              echo "âŒ Could not retrieve Redis endpoint from Terraform state"
              echo "ğŸ’¡ Make sure Terraform infrastructure is deployed first"
              exit 1
            fi
          else
            CLUSTER_NAME="${{ needs.terraform-apply.outputs.cluster-name }}"
            REDIS_ENDPOINT="${{ needs.terraform-apply.outputs.redis-endpoint }}"
          fi
          
          # Create environment configuration for the script
          cat > ../livekit.env << EOF
          # Pipeline Configuration - Auto-generated
          AWS_REGION=${{ env.AWS_REGION }}
          CLUSTER_NAME=$CLUSTER_NAME
          
          # LiveKit API Credentials
          API_KEY=APIKmrHi78hxpbd
          SECRET_KEY=Y3vpZUiNQyC8DdQevWeIdzfMgmjs5hUycqJA22atniuB
          
          # Kubernetes Configuration
          NAMESPACE=livekit
          RELEASE_NAME=livekit
          
          # Autoscaling Configuration
          MIN_REPLICAS=1
          MAX_REPLICAS=20
          CPU_THRESHOLD=75
          
          # Resource Configuration
          CPU_REQUEST=500m
          CPU_LIMIT=2000m
          MEMORY_REQUEST=1Gi
          MEMORY_LIMIT=2Gi
          
          # LoadBalancer Configuration
          LB_TIMEOUT=600
          HEALTH_CHECK_TIMEOUT=300
          EOF
          
          echo "ğŸ“‹ Configuration created for environment: ${{ inputs.environment }}"
          echo "ğŸ“‹ Cluster: $CLUSTER_NAME"
          echo "ğŸ“‹ Redis: $REDIS_ENDPOINT"
          
          # Run the deployment script
          ./03-deploy-livekit.sh

  # DESTROY: Remove everything (Optional)
  destroy:
    name: ğŸ—‘ï¸ Destroy LiveKit Infrastructure
    runs-on: ubuntu-latest
    if: ${{ inputs.action == 'destroy' }}
    environment: livekit-poc-${{ inputs.environment }}-destroy
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          role-session-name: GitHubActions-LiveKit-Destroy-${{ github.run_id }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Tools
        run: |
          wget -q https://releases.hashicorp.com/terraform/1.10.3/terraform_1.10.3_linux_amd64.zip
          unzip -q terraform_1.10.3_linux_amd64.zip
          sudo mv terraform /usr/local/bin/
          
          curl -LO "https://dl.k8s.io/release/v1.30.0/bin/linux/amd64/kubectl"
          sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
          
          curl -fsSL https://get.helm.sh/helm-v3.16.3-linux-amd64.tar.gz | tar -xz
          sudo mv linux-amd64/helm /usr/local/bin/

      - name: ğŸ—‘ï¸ Destroy All Infrastructure
        working-directory: resources
        run: |
          echo "ğŸ—‘ï¸ Destroying all infrastructure with Terraform..."
          
          terraform init -backend-config="../environments/livekit-poc/${{ env.AWS_REGION }}/${{ inputs.environment }}/backend.tfvars"
          
          # Run destroy with retries
          MAX_ATTEMPTS=3
          ATTEMPT=1
          
          while [ $ATTEMPT -le $MAX_ATTEMPTS ]; do
            echo "ğŸ”„ Destroy attempt $ATTEMPT/$MAX_ATTEMPTS..."
            
            if terraform destroy \
              -var-file="../environments/livekit-poc/${{ env.AWS_REGION }}/${{ inputs.environment }}/inputs.tfvars" \
              -var="deployment_role_arn=${{ secrets.DEPLOYMENT_ROLE_ARN }}" \
              -auto-approve; then
              echo "âœ… All infrastructure destroyed!"
              exit 0
            else
              echo "âš ï¸ Destroy attempt $ATTEMPT failed"
              
              if [ $ATTEMPT -eq $MAX_ATTEMPTS ]; then
                echo "âŒ Destroy failed after $MAX_ATTEMPTS attempts"
                exit 1
              fi
              
              echo "â³ Waiting 10 seconds before retry..."
              sleep 10
              ATTEMPT=$((ATTEMPT + 1))
            fi
          done