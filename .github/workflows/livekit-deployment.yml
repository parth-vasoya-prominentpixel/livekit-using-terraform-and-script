name: üé• LiveKit Deployment Pipeline

on:
  workflow_dispatch:
    inputs:
      action:
        description: 'Action to perform'
        required: true
        default: 'deploy'
        type: choice
        options:
          - deploy
          - destroy
      environment:
        description: 'Environment'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - uat
          - prod
      skip_prerequisites:
        description: 'Skip Prerequisites Check'
        required: false
        default: false
        type: boolean
      skip_terraform_plan:
        description: 'Skip Terraform Plan'
        required: false
        default: false
        type: boolean
      skip_terraform_apply:
        description: 'Skip Terraform Apply'
        required: false
        default: false
        type: boolean
      skip_livekit:
        description: 'Skip Load Balancer Controller Setup'
        required: false
        default: false
        type: boolean

env:
  AWS_REGION: us-east-1

permissions:
  id-token: write
  contents: read

jobs:
  # Step 1: Prerequisites (Optional)
  prerequisites:
    name: üîß Step 1 - Prerequisites
    runs-on: ubuntu-latest
    if: ${{ inputs.action == 'deploy' && !inputs.skip_prerequisites }}
    environment: livekit-poc-${{ inputs.environment }}-prerequisites
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          role-session-name: GitHubActions-Prerequisites-${{ github.run_id }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Tools
        run: |
          # Setup Terraform
          wget -q https://releases.hashicorp.com/terraform/1.10.3/terraform_1.10.3_linux_amd64.zip
          unzip -q terraform_1.10.3_linux_amd64.zip
          sudo mv terraform /usr/local/bin/
          
          # Setup kubectl
          curl -LO "https://dl.k8s.io/release/v1.30.0/bin/linux/amd64/kubectl"
          sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
          
          # Setup Helm
          curl -fsSL https://get.helm.sh/helm-v3.16.3-linux-amd64.tar.gz | tar -xz
          sudo mv linux-amd64/helm /usr/local/bin/
          
          # Setup eksctl
          curl -sLO "https://github.com/eksctl-io/eksctl/releases/download/v0.191.0/eksctl_Linux_amd64.tar.gz"
          tar -xzf eksctl_Linux_amd64.tar.gz
          sudo mv eksctl /usr/local/bin/

      - name: Run Prerequisites Script
        working-directory: scripts
        run: |
          chmod +x 00-prerequisites.sh
          ./00-prerequisites.sh

  # Step 2: Terraform Plan (Optional)
  terraform-plan:
    name: üìã Step 2 - Terraform Plan
    runs-on: ubuntu-latest
    needs: [prerequisites]
    if: ${{ always() && inputs.action == 'deploy' && !inputs.skip_terraform_plan && (needs.prerequisites.result == 'success' || inputs.skip_prerequisites) }}
    environment: livekit-poc-${{ inputs.environment }}-terraform-plan
    outputs:
      plan-output: ${{ steps.plan.outputs.plan_output }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          role-session-name: GitHubActions-Terraform-Plan-${{ github.run_id }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform-version: 1.10.3

      - name: Terraform Plan
        id: plan
        working-directory: resources
        run: |
          echo "üìã Running Terraform Plan..."
          
          terraform init -backend-config="../environments/livekit-poc/${{ env.AWS_REGION }}/${{ inputs.environment }}/backend.tfvars"
          
          terraform plan \
            -var-file="../environments/livekit-poc/${{ env.AWS_REGION }}/${{ inputs.environment }}/inputs.tfvars" \
            -var="deployment_role_arn=${{ secrets.DEPLOYMENT_ROLE_ARN }}" \
            -out=tfplan
          
          echo "‚úÖ Terraform plan completed successfully!"

  # Step 3: Terraform Apply (Optional)
  terraform-apply:
    name: üöÄ Step 3 - Terraform Apply
    runs-on: ubuntu-latest
    needs: [terraform-plan]
    if: ${{ always() && inputs.action == 'deploy' && !inputs.skip_terraform_apply && (needs.terraform-plan.result == 'success' || inputs.skip_terraform_plan) }}
    environment: livekit-poc-${{ inputs.environment }}-terraform-apply
    outputs:
      cluster-name: ${{ steps.apply.outputs.cluster_name }}
      redis-endpoint: ${{ steps.apply.outputs.redis_endpoint }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          role-session-name: GitHubActions-Terraform-Apply-${{ github.run_id }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform-version: 1.10.3

      - name: Terraform Apply
        id: apply
        working-directory: resources
        run: |
          echo "üöÄ Applying Terraform configuration..."
          
          terraform init -backend-config="../environments/livekit-poc/${{ env.AWS_REGION }}/${{ inputs.environment }}/backend.tfvars"
          
          terraform plan \
            -var-file="../environments/livekit-poc/${{ env.AWS_REGION }}/${{ inputs.environment }}/inputs.tfvars" \
            -var="deployment_role_arn=${{ secrets.DEPLOYMENT_ROLE_ARN }}" \
            -out=tfplan
          
          terraform apply tfplan
          
          # Get outputs
          CLUSTER_NAME=$(terraform output -raw cluster_name)
          REDIS_ENDPOINT=$(terraform output -raw redis_cluster_endpoint)
          
          echo "cluster_name=$CLUSTER_NAME" >> $GITHUB_OUTPUT
          echo "redis_endpoint=$REDIS_ENDPOINT" >> $GITHUB_OUTPUT
          
          echo "‚úÖ Infrastructure deployed successfully!"
          echo "üìä Cluster: $CLUSTER_NAME"
          echo "üìä Redis: $REDIS_ENDPOINT"

  # Step 4: Setup AWS Load Balancer Controller
  setup-load-balancer-controller:
    name: üîß Step 4 - Setup AWS Load Balancer Controller
    runs-on: ubuntu-latest
    needs: [terraform-apply]
    if: ${{ always() && inputs.action == 'deploy' && !inputs.skip_livekit && (needs.terraform-apply.result == 'success' || inputs.skip_terraform_apply) }}
    environment: livekit-poc-${{ inputs.environment }}-load-balancer
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          role-session-name: GitHubActions-LoadBalancer-${{ github.run_id }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Tools
        run: |
          # Install kubectl
          curl -LO "https://dl.k8s.io/release/v1.30.0/bin/linux/amd64/kubectl"
          sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
          
          # Install Helm
          curl -fsSL https://get.helm.sh/helm-v3.16.3-linux-amd64.tar.gz | tar -xz
          sudo mv linux-amd64/helm /usr/local/bin/
          
          # Install eksctl
          curl -sLO "https://github.com/eksctl-io/eksctl/releases/download/v0.191.0/eksctl_Linux_amd64.tar.gz"
          tar -xzf eksctl_Linux_amd64.tar.gz
          sudo mv eksctl /usr/local/bin/
          
          # Install jq and curl
          sudo apt-get update && sudo apt-get install -y jq curl
          
          # Verify installations
          echo "‚úÖ Tool versions:"
          kubectl version --client
          helm version
          eksctl version
          jq --version

      - name: Setup AWS Load Balancer Controller
        working-directory: scripts
        run: |
          chmod +x 02-setup-load-balancer-controller.sh
          
          # Determine cluster name
          if [ "${{ inputs.skip_terraform_apply }}" = "true" ]; then
            CLUSTER_NAME="lp-eks-livekit-use1-${{ inputs.environment }}"
          else
            CLUSTER_NAME="${{ needs.terraform-apply.outputs.cluster-name }}"
          fi
          
          echo "üìã Configuration for Load Balancer Controller Setup:"
          echo "üìã Cluster: $CLUSTER_NAME"
          echo "üìã Region: ${{ env.AWS_REGION }}"
          echo "üìã Environment: ${{ inputs.environment }}"
          echo ""
          
          # Enable full logging and continuous output
          set -x  # Enable command tracing
          
          # Run the Load Balancer Controller setup with full logging
          CLUSTER_NAME="$CLUSTER_NAME" \
          AWS_REGION="${{ env.AWS_REGION }}" \
          ENVIRONMENT="${{ inputs.environment }}" \
          ./02-setup-load-balancer-controller.sh 2>&1 | tee /tmp/lbc-setup.log
          
          # Show final status
          echo ""
          echo "üîç Final Status Check:"
          kubectl get deployment aws-load-balancer-controller -n kube-system || echo "Deployment not found"
          kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller || echo "No pods found"
          kubectl get service aws-load-balancer-webhook-service -n kube-system || echo "Webhook service not found"
          
          echo ""
          echo "üìã Setup Log Summary:"
          echo "‚úÖ Load Balancer Controller setup completed"
          echo "üìÑ Full logs available in pipeline output above"

      - name: Upload Setup Logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: load-balancer-controller-setup-logs-${{ inputs.environment }}
          path: /tmp/lbc-setup.log
          retention-days: 7

  # DESTROY: Remove everything (Optional)
  destroy:
    name: üóëÔ∏è Destroy LiveKit Infrastructure
    runs-on: ubuntu-latest
    if: ${{ inputs.action == 'destroy' }}
    environment: livekit-poc-${{ inputs.environment }}-destroy
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          role-session-name: GitHubActions-LiveKit-Destroy-${{ github.run_id }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Tools
        run: |
          wget -q https://releases.hashicorp.com/terraform/1.10.3/terraform_1.10.3_linux_amd64.zip
          unzip -q terraform_1.10.3_linux_amd64.zip
          sudo mv terraform /usr/local/bin/
          
          curl -LO "https://dl.k8s.io/release/v1.30.0/bin/linux/amd64/kubectl"
          sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
          
          curl -fsSL https://get.helm.sh/helm-v3.16.3-linux-amd64.tar.gz | tar -xz
          sudo mv linux-amd64/helm /usr/local/bin/

      - name: üóëÔ∏è Destroy All Infrastructure
        working-directory: resources
        run: |
          echo "üóëÔ∏è Destroying all infrastructure with Terraform..."
          
          terraform init -backend-config="../environments/livekit-poc/${{ env.AWS_REGION }}/${{ inputs.environment }}/backend.tfvars"
          
          # Run destroy with retries
          MAX_ATTEMPTS=3
          ATTEMPT=1
          
          while [ $ATTEMPT -le $MAX_ATTEMPTS ]; do
            echo "üîÑ Destroy attempt $ATTEMPT/$MAX_ATTEMPTS..."
            
            if terraform destroy \
              -var-file="../environments/livekit-poc/${{ env.AWS_REGION }}/${{ inputs.environment }}/inputs.tfvars" \
              -var="deployment_role_arn=${{ secrets.DEPLOYMENT_ROLE_ARN }}" \
              -auto-approve; then
              echo "‚úÖ All infrastructure destroyed!"
              exit 0
            else
              echo "‚ö†Ô∏è Destroy attempt $ATTEMPT failed"
              
              if [ $ATTEMPT -eq $MAX_ATTEMPTS ]; then
                echo "‚ùå Destroy failed after $MAX_ATTEMPTS attempts"
                exit 1
              fi
              
              echo "‚è≥ Waiting 10 seconds before retry..."
              sleep 10
              ATTEMPT=$((ATTEMPT + 1))
            fi
          done