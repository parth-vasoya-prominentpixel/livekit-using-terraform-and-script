#!/bin/bash

# AWS Load Balancer Controller Setup Script - Smart Version
# Uses existing resources when available, creates only what's needed
# Version: AWS Load Balancer Controller v2.8.0

set -e

echo "âš–ï¸ AWS Load Balancer Controller Setup - Smart Version"
echo "===================================================="
echo "ðŸ“‹ Uses existing resources when available"
echo "ðŸŽ¯ Creates only what's needed"

# Check if CLUSTER_NAME is provided
if [ -z "$CLUSTER_NAME" ]; then
    echo "âŒ CLUSTER_NAME environment variable is required"
    echo ""
    echo "Usage:"
    echo "  export CLUSTER_NAME=your-cluster-name"
    echo "  export AWS_REGION=us-east-1  # optional"
    echo "  ./02-setup-load-balancer.sh"
    echo ""
    exit 1
fi

# Set AWS region
AWS_REGION=${AWS_REGION:-us-east-1}

echo ""
echo "ðŸ“‹ Configuration:"
echo "   Cluster Name: $CLUSTER_NAME"
echo "   AWS Region: $AWS_REGION"
echo "   Mode: Smart (use existing resources)"

# Get AWS account ID
echo ""
echo "ðŸ” Getting AWS account information..."
if ! AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text 2>/dev/null); then
    echo "âŒ Failed to get AWS account ID. Check AWS credentials."
    exit 1
fi
echo "âœ… AWS Account ID: $AWS_ACCOUNT_ID"

# Quick cluster verification
echo ""
echo "ðŸ” Verifying cluster..."
CLUSTER_STATUS=$(aws eks describe-cluster --name "$CLUSTER_NAME" --region "$AWS_REGION" --query 'cluster.status' --output text 2>/dev/null || echo "NOT_FOUND")

if [ "$CLUSTER_STATUS" != "ACTIVE" ]; then
    echo "âŒ Cluster '$CLUSTER_NAME' is not ACTIVE (status: $CLUSTER_STATUS)"
    exit 1
fi
echo "âœ… Cluster is ACTIVE"

# Update kubeconfig
echo ""
echo "ðŸ”§ Updating kubeconfig..."
aws eks update-kubeconfig --region "$AWS_REGION" --name "$CLUSTER_NAME" >/dev/null 2>&1
echo "âœ… Kubeconfig updated"

# Test kubectl
echo ""
echo "ðŸ” Testing kubectl..."
if ! timeout 10 kubectl get nodes >/dev/null 2>&1; then
    echo "âŒ Cannot connect to cluster"
    exit 1
fi
echo "âœ… kubectl working"

# Get VPC ID
VPC_ID=$(aws eks describe-cluster --name "$CLUSTER_NAME" --region "$AWS_REGION" --query 'cluster.resourcesVpcConfig.vpcId' --output text)
echo "âœ… VPC ID: $VPC_ID"

# Step 1: Check IAM Policy
echo ""
echo "ðŸ“‹ Step 1: Checking IAM Policy..."
POLICY_ARN="arn:aws:iam::$AWS_ACCOUNT_ID:policy/AWSLoadBalancerControllerIAMPolicy"

if aws iam get-policy --policy-arn "$POLICY_ARN" >/dev/null 2>&1; then
    echo "âœ… IAM policy exists: AWSLoadBalancerControllerIAMPolicy"
else
    echo "ðŸ“‹ Creating IAM policy..."
    
    # Download and create policy
    curl -sS -o iam_policy.json https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.8.0/docs/install/iam_policy.json
    
    if aws iam create-policy \
        --policy-name AWSLoadBalancerControllerIAMPolicy \
        --policy-document file://iam_policy.json >/dev/null 2>&1; then
        echo "âœ… IAM policy created"
    else
        echo "âŒ Failed to create IAM policy"
        exit 1
    fi
    
    rm -f iam_policy.json
fi

# Step 2: Check Service Account
echo ""
echo "ðŸ“‹ Step 2: Checking Service Account..."
SA_NAME="aws-load-balancer-controller"

if kubectl get serviceaccount "$SA_NAME" -n kube-system >/dev/null 2>&1; then
    echo "âœ… Service account exists: $SA_NAME"
    
    # Check if it has IAM role
    SA_ROLE=$(kubectl get serviceaccount "$SA_NAME" -n kube-system -o jsonpath='{.metadata.annotations.eks\.amazonaws\.com/role-arn}' 2>/dev/null || echo "")
    if [ -n "$SA_ROLE" ]; then
        echo "âœ… Service account has IAM role: $(basename "$SA_ROLE")"
    else
        echo "âš ï¸ Service account has no IAM role (using node permissions)"
    fi
    echo "ðŸŽ¯ Using existing service account"
    
else
    echo "ðŸ“‹ Creating service account..."
    
    # Create with eksctl (simple approach)
    if eksctl create iamserviceaccount \
        --cluster="$CLUSTER_NAME" \
        --namespace=kube-system \
        --name="$SA_NAME" \
        --attach-policy-arn="$POLICY_ARN" \
        --region="$AWS_REGION" \
        --approve >/dev/null 2>&1; then
        echo "âœ… Service account created"
    else
        echo "âš ï¸ eksctl failed, checking if service account exists anyway..."
        if kubectl get serviceaccount "$SA_NAME" -n kube-system >/dev/null 2>&1; then
            echo "âœ… Service account exists (created by previous run)"
        else
            echo "âŒ Failed to create service account"
            exit 1
        fi
    fi
fi

# Step 3: Install/Check Load Balancer Controller
echo ""
echo "ðŸ“‹ Step 3: Checking Load Balancer Controller..."

# Add Helm repo
helm repo add eks https://aws.github.io/eks-charts >/dev/null 2>&1 || true
helm repo update >/dev/null 2>&1

# Check if controller is already installed and healthy
EXISTING_CONTROLLERS=$(kubectl get deployment -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller --no-headers 2>/dev/null | wc -l)

if [ "$EXISTING_CONTROLLERS" -gt 0 ]; then
    echo "âœ… Found $EXISTING_CONTROLLERS load balancer controller(s)"
    
    # Check if any are healthy
    HEALTHY_FOUND=false
    kubectl get deployment -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller --no-headers 2>/dev/null | while read name ready rest; do
        if [[ "$ready" == *"/"* ]]; then
            READY_COUNT=$(echo "$ready" | cut -d'/' -f1)
            DESIRED_COUNT=$(echo "$ready" | cut -d'/' -f2)
            if [ "$READY_COUNT" = "$DESIRED_COUNT" ] && [ "$READY_COUNT" != "0" ]; then
                echo "âœ… Controller '$name' is healthy ($ready)"
                HEALTHY_FOUND=true
                break
            fi
        fi
    done
    
    if [ "$HEALTHY_FOUND" = true ]; then
        echo "ðŸŽ‰ Load balancer controller is already working!"
        echo "âœ… Setup completed - using existing healthy controller"
        exit 0
    else
        echo "âš ï¸ Controllers exist but none are healthy, installing new one..."
    fi
fi

# Install new controller
echo "ðŸš€ Installing AWS Load Balancer Controller..."
RELEASE_NAME="aws-load-balancer-controller"
CHART_VERSION="1.8.0"

# Check if release already exists
if helm list -n kube-system | grep -q "$RELEASE_NAME"; then
    echo "ðŸ”„ Upgrading existing release..."
    HELM_ACTION="upgrade"
else
    echo "ðŸ“¦ Installing new release..."
    HELM_ACTION="install"
fi

if helm "$HELM_ACTION" "$RELEASE_NAME" eks/aws-load-balancer-controller \
    -n kube-system \
    --set clusterName="$CLUSTER_NAME" \
    --set serviceAccount.create=false \
    --set serviceAccount.name="$SA_NAME" \
    --set region="$AWS_REGION" \
    --set vpcId="$VPC_ID" \
    --version "$CHART_VERSION" \
    --wait --timeout=5m >/dev/null 2>&1; then
    
    echo "âœ… Load balancer controller $HELM_ACTION completed"
else
    echo "âŒ Helm $HELM_ACTION failed"
    
    # Show basic troubleshooting info
    echo "ðŸ“‹ Current status:"
    kubectl get deployment -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller 2>/dev/null || echo "   No deployments found"
    kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller 2>/dev/null || echo "   No pods found"
    
    exit 1
fi

# Quick verification
echo ""
echo "ðŸ“‹ Verification..."
if kubectl wait --for=condition=available deployment -l app.kubernetes.io/name=aws-load-balancer-controller -n kube-system --timeout=60s >/dev/null 2>&1; then
    echo "âœ… Controller is ready!"
    
    # Show final status
    RUNNING_PODS=$(kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller --no-headers 2>/dev/null | grep -c "Running" || echo "0")
    echo "ðŸ“Š Running pods: $RUNNING_PODS"
    
else
    echo "âš ï¸ Controller may still be starting up"
    kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller 2>/dev/null || echo "   No pods found"
fi

echo ""
echo "ðŸŽ‰ AWS Load Balancer Controller Setup Completed!"
echo "=============================================="
echo ""
echo "ðŸ“‹ Summary:"
echo "   âœ… Cluster: $CLUSTER_NAME"
echo "   âœ… IAM Policy: AWSLoadBalancerControllerIAMPolicy"
echo "   âœ… Service Account: $SA_NAME"
echo "   âœ… Controller: Ready for load balancer provisioning"
echo ""
echo "ðŸ“‹ Next Steps:"
echo "   1. Deploy applications with LoadBalancer services"
echo "   2. Controller will automatically create AWS load balancers"
echo "   3. Monitor with: kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller"
echo ""
echo "ðŸ’¡ This setup uses existing resources when available"